function gradient(lm::AbstractModel, ce::CrossEntropy, X::Matrix, Y::Vector)
	∇W = zero(lm.W) # gradients should be the size of the weights
	θ = predict(lm, X)
	Z=sigmoid(θ)
	#### BEGIN SOLUTION
	
	for i in 1:size(∇W,1)
		for j in 1:size(Z,1)
			∇W[i] = ∇W[i]+(Z[j] - Y[j])*X[j,i]
		end
	end
	∇W=1/size(Z,1)*∇W
	# ### END SOLUTION

	@assert size(∇W) == size(lm.W)
	∇W
end;


function loss(lm::AbstractModel, ce::CrossEntropy, X , Y)
	θ = predict(lm, X) # θ = XW'
	loss = 0.0
	
	#### BEGIN SOLUTION
	
	s=0
	
	Z=sigmoid(θ)
	
	for i in 1:size(Z,1)
		s=s + (Y[i] * log.(Z[i]) + (1.0 -Y[i]) * log.(1.0 - Z[i]))
	end
	
	ce=-1/size(X,1)*s

   

	
	#### END SOLUTION
end;

function update!(lm::LinearModel, 
				 lf::LossFunction,
				 opt::RMSprop,
				 x::Matrix,
				 y::Vector)

	g = gradient(lm, lf, x, y)
	if size(g) !== size(opt.G) # need to make sure this is of the right shape.
		opt.G = zero(g)
	end
	
	# update opt.v and lm.W
	η, β, G, ϵ = opt.η, opt.β, opt.G, opt.ϵ
	
	#### BEGIN SOLUTION
	opt.G=opt.β* G+(1-β)*g.^2 
	for i in 1:size(lm.W,1) 
		lm.W[i]-=g[i]*opt.η/sqrt(opt.G[i]+opt.ϵ)
	end

	#### END SOLUTION
	
end;